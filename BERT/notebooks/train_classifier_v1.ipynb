{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Initialization and imports"
      ],
      "metadata": {
        "id": "Mki7ScNpmlGW"
      },
      "id": "Mki7ScNpmlGW"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d0b32d3d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0b32d3d",
        "outputId": "617f5077-b227-4ab1-b43b-7e935e827eec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully installed adapters-1.2.0 alembic-1.16.4 databricks-sdk-0.62.0 docker-7.1.0 graphene-3.4.3 graphql-core-3.2.6 graphql-relay-3.2.0 gunicorn-23.0.0 langid-1.1.6 mlflow-3.2.0 mlflow-skinny-3.2.0 mlflow-tracing-3.2.0 opentelemetry-api-1.36.0 opentelemetry-sdk-1.36.0 opentelemetry-semantic-conventions-0.57b0 pyaml-25.7.0 scikit-optimize-0.10.2 transformers-4.51.3\n"
          ]
        }
      ],
      "source": [
        "#Celda exclusiva colab:\n",
        "#\"\"\"\n",
        "#Instalar dependencias\n",
        "!pip install transformers adapters langid scikit-optimize mlflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content')\n",
        "!rm -rf VRID_language_proyect\n",
        "!rm -rf VRID_language_proyect\n",
        "!git clone --branch dev_Alonso --single-branch https://github.com/jitalo333/VRID_language_proyect\n",
        "#Moverse a repositorio\n",
        "os.chdir('/content/VRID_language_proyect/BERT')\n",
        "#Montar drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "#\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvicXPekEL04",
        "outputId": "41490e91-c125-49b6-b5e7-f9d73ff8ed98"
      },
      "id": "xvicXPekEL04",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'VRID_language_proyect'...\n",
            "remote: Enumerating objects: 93, done.\u001b[K\n",
            "remote: Counting objects: 100% (93/93), done.\u001b[K\n",
            "remote: Compressing objects: 100% (67/67), done.\u001b[K\n",
            "remote: Total 93 (delta 33), reused 80 (delta 23), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (93/93), 1.28 MiB | 8.02 MiB/s, done.\n",
            "Resolving deltas: 100% (33/33), done.\n",
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "c94180a1",
      "metadata": {
        "id": "c94180a1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from preprocess import preprocess_record\n",
        "from translate import translator\n",
        "from encoder import embed_texts, prepare_data\n",
        "\n",
        "#Train model\n",
        "import ast\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "from ML_pipeline_skp import get_est_params_dict, run_bayesian_pipeline, eval_model, safe_log_metric\n",
        "from ML_pipeline_skp import mlflow_ckeckpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a15e37a",
      "metadata": {
        "id": "5a15e37a"
      },
      "source": [
        "# 1) Preprocesamiento de los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b184a05",
      "metadata": {
        "id": "5b184a05"
      },
      "outputs": [],
      "source": [
        "# 1) Cargar datos\n",
        "path = \"\"\n",
        "filePATH = os.path.join(path, \"data_concatenada.xlsx\")\n",
        "df = pd.read_excel(filePATH,\n",
        "                   usecols=[\"Código VRID\", \"Título\", \"Resumen\", \"Keywords\", \"Interdisciplinario\", \"Transdisciplinario\"]) \\\n",
        "       .fillna(\"\")\n",
        "# 2) Preprocesar los datos\n",
        "cols = [\"Título\", \"Resumen\", \"Keywords\"]\n",
        "df[cols] = df[cols].applymap(lambda x: \"\" if str(x).strip().upper() == \"DESCONOCIDO\" else str(x).strip())\n",
        "df[\"text_for_embedding\"] = df.apply(\n",
        "    lambda r: preprocess_record(r[\"Título\"], r[\"Resumen\"], r[\"Keywords\"]),\n",
        "    axis=1\n",
        ")\n",
        "df.to_excel(\"data_preprocessed.xlsx\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "850b5354",
      "metadata": {
        "id": "850b5354"
      },
      "source": [
        "# 2) Traducción del texto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4c5555d",
      "metadata": {
        "id": "a4c5555d"
      },
      "outputs": [],
      "source": [
        "trans = translator()\n",
        "df[\"text_for_embedding_translated\"] = df.apply(\n",
        "    lambda r: trans.detect_and_translate(r.get(\"text_for_embedding\", \"\")),\n",
        "    axis=1\n",
        ")\n",
        "df.to_excel(\"data_translated.xlsx\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "793467d4",
      "metadata": {
        "id": "793467d4"
      },
      "source": [
        "# 3) Embedding text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77d8d6a9",
      "metadata": {
        "id": "77d8d6a9"
      },
      "outputs": [],
      "source": [
        "# 1) Preparar textos y etiquetas\n",
        "texts, labels = prepare_data(df)\n",
        "\n",
        "# 2) Calcular embeddings\n",
        "# Parámetros modelo\n",
        "BASE_MODEL = \"allenai/specter2_base\"\n",
        "ADAPTER_NAME = \"allenai/specter2\"\n",
        "\n",
        "emb_texts = embed_texts(texts, BASE_MODEL, ADAPTER_NAME)\n",
        "\n",
        "# 3) Guardar embeddings y etiquetas\n",
        "df_dataset = pd.DataFrame(columns=[\"Código VRID\", \"labels\", \"embedings\"])\n",
        "df_dataset[\"Código VRID\"] = df.loc[labels.index, \"Código VRID\"]\n",
        "df_dataset[\"labels\"] = labels\n",
        "df_dataset[\"embedings\"] = emb_texts.tolist()\n",
        "df_dataset.to_excel(\"dataset_embed_translated.xlsx\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4) Train classifier"
      ],
      "metadata": {
        "id": "of6LwMGfXHPc"
      },
      "id": "of6LwMGfXHPc"
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/VRID_NLP/code/VRID_proyect/\"\n",
        "filePATH = os.path.join(path, \"dataset_embed_translated.xlsx\")\n",
        "df = pd.read_excel(filePATH)\n",
        "df['embedings'] = df['embedings'].apply(lambda x: np.array(ast.literal_eval(x)))\n",
        "df.head()\n",
        "\n",
        "\n",
        "y = df['labels'].to_numpy()\n",
        "X = df['embedings'].to_numpy()\n",
        "X = np.vstack(X)\n",
        "\n",
        "seed = 7\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=seed, stratify=y)\n",
        "\n",
        "# 2. Elegir modelos a probar\n",
        "model_keys = [\n",
        "    #'LogisticRegression',\n",
        "    #'DecisionTreeClassifier',\n",
        "    'RandomForestClassifier',\n",
        "    #'GradientBoostingClassifier',\n",
        "    'XGBClassifier',\n",
        "    #'MLPClassifier',\n",
        "    #'SVC',\n",
        "    #'SGDClassifier'\n",
        "]\n",
        "\n",
        "# 3. Obtener el diccionario de modelos y parámetros\n",
        "est_params_dict = get_est_params_dict(model_keys)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(\"📊 Comienzo:\", Counter(y_train))\n",
        "print(\"📊 Comienzo:\", Counter(y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m01K6uVvXLij",
        "outputId": "12cf7805-152e-4563-95d0-def80f1f7862"
      },
      "id": "m01K6uVvXLij",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(867, 768)\n",
            "(97, 768)\n",
            "📊 Comienzo: Counter({np.int64(1): 499, np.int64(0): 368})\n",
            "📊 Comienzo: Counter({np.int64(1): 56, np.int64(0): 41})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Ejecutar entrenamiento, validación y test con tus funciones\n",
        "results_val, models_dicc = run_bayesian_pipeline(est_params_dict, X_train, y_train, n_iter=2, sample_weight_On = True)\n",
        "\n",
        "print(results_val)\n",
        "for model in models_dicc.values():\n",
        "  results_test = eval_model(model, X_test, y_test)\n",
        "  print(results_test)\n",
        "\n",
        "experiment_name = 'test_functions'\n",
        "mlflow_ckeckpoint(results_val, models_dicc, X_test, y_test, experiment_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ax6NUkxYN_9",
        "outputId": "c97aa39d-2077-41da-f73d-7c307d1809ed"
      },
      "id": "1ax6NUkxYN_9",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier\n",
            "Compute sw\n",
            "XGBClassifier\n",
            "Compute sw\n",
            "{'RandomForestClassifier': {'mean_test_score': 0.83, 'std_test_score': 0.03}, 'XGBClassifier': {'mean_test_score': 0.72, 'std_test_score': 0.04}}\n",
            "{'accuracy': 0.7010309278350515, 'precision': 0.6956521739130435, 'recall': 0.8571428571428571, 'f1_score': 0.768, 't_n': np.int64(20), 'f_p': np.int64(21), 'f_n': np.int64(8), 't_p': np.int64(48)}\n",
            "{'accuracy': 0.711340206185567, 'precision': 0.7333333333333333, 'recall': 0.7857142857142857, 'f1_score': 0.7586206896551724, 't_n': np.int64(25), 'f_p': np.int64(16), 'f_n': np.int64(12), 't_p': np.int64(44)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/08/08 17:14:24 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
            "2025/08/08 17:14:24 INFO mlflow.store.db.utils: Updating database tables\n",
            "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
            "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
            "INFO  [alembic.runtime.migration] Running upgrade  -> 451aebb31d03, add metric step\n",
            "INFO  [alembic.runtime.migration] Running upgrade 451aebb31d03 -> 90e64c465722, migrate user column to tags\n",
            "INFO  [alembic.runtime.migration] Running upgrade 90e64c465722 -> 181f10493468, allow nulls for metric values\n",
            "INFO  [alembic.runtime.migration] Running upgrade 181f10493468 -> df50e92ffc5e, Add Experiment Tags Table\n",
            "INFO  [alembic.runtime.migration] Running upgrade df50e92ffc5e -> 7ac759974ad8, Update run tags with larger limit\n",
            "INFO  [alembic.runtime.migration] Running upgrade 7ac759974ad8 -> 89d4b8295536, create latest metrics table\n",
            "INFO  [89d4b8295536_create_latest_metrics_table_py] Migration complete!\n",
            "INFO  [alembic.runtime.migration] Running upgrade 89d4b8295536 -> 2b4d017a5e9b, add model registry tables to db\n",
            "INFO  [2b4d017a5e9b_add_model_registry_tables_to_db_py] Adding registered_models and model_versions tables to database.\n",
            "INFO  [2b4d017a5e9b_add_model_registry_tables_to_db_py] Migration complete!\n",
            "INFO  [alembic.runtime.migration] Running upgrade 2b4d017a5e9b -> cfd24bdc0731, Update run status constraint with killed\n",
            "INFO  [alembic.runtime.migration] Running upgrade cfd24bdc0731 -> 0a8213491aaa, drop_duplicate_killed_constraint\n",
            "INFO  [alembic.runtime.migration] Running upgrade 0a8213491aaa -> 728d730b5ebd, add registered model tags table\n",
            "INFO  [alembic.runtime.migration] Running upgrade 728d730b5ebd -> 27a6a02d2cf1, add model version tags table\n",
            "INFO  [alembic.runtime.migration] Running upgrade 27a6a02d2cf1 -> 84291f40a231, add run_link to model_version\n",
            "INFO  [alembic.runtime.migration] Running upgrade 84291f40a231 -> a8c4a736bde6, allow nulls for run_id\n",
            "INFO  [alembic.runtime.migration] Running upgrade a8c4a736bde6 -> 39d1c3be5f05, add_is_nan_constraint_for_metrics_tables_if_necessary\n",
            "INFO  [alembic.runtime.migration] Running upgrade 39d1c3be5f05 -> c48cb773bb87, reset_default_value_for_is_nan_in_metrics_table_for_mysql\n",
            "INFO  [alembic.runtime.migration] Running upgrade c48cb773bb87 -> bd07f7e963c5, create index on run_uuid\n",
            "INFO  [alembic.runtime.migration] Running upgrade bd07f7e963c5 -> 0c779009ac13, add deleted_time field to runs table\n",
            "INFO  [alembic.runtime.migration] Running upgrade 0c779009ac13 -> cc1f77228345, change param value length to 500\n",
            "INFO  [alembic.runtime.migration] Running upgrade cc1f77228345 -> 97727af70f4d, Add creation_time and last_update_time to experiments table\n",
            "INFO  [alembic.runtime.migration] Running upgrade 97727af70f4d -> 3500859a5d39, Add Model Aliases table\n",
            "INFO  [alembic.runtime.migration] Running upgrade 3500859a5d39 -> 7f2a7d5fae7d, add datasets inputs input_tags tables\n",
            "INFO  [alembic.runtime.migration] Running upgrade 7f2a7d5fae7d -> 2d6e25af4d3e, increase max param val length from 500 to 8000\n",
            "INFO  [alembic.runtime.migration] Running upgrade 2d6e25af4d3e -> acf3f17fdcc7, add storage location field to model versions\n",
            "INFO  [alembic.runtime.migration] Running upgrade acf3f17fdcc7 -> 867495a8f9d4, add trace tables\n",
            "INFO  [alembic.runtime.migration] Running upgrade 867495a8f9d4 -> 5b0e9adcef9c, add cascade deletion to trace tables foreign keys\n",
            "INFO  [alembic.runtime.migration] Running upgrade 5b0e9adcef9c -> 4465047574b1, increase max dataset schema size\n",
            "INFO  [alembic.runtime.migration] Running upgrade 4465047574b1 -> f5a4f2784254, increase run tag value limit to 8000\n",
            "INFO  [alembic.runtime.migration] Running upgrade f5a4f2784254 -> 0584bdc529eb, add cascading deletion to datasets from experiments\n",
            "INFO  [alembic.runtime.migration] Running upgrade 0584bdc529eb -> 400f98739977, add logged model tables\n",
            "INFO  [alembic.runtime.migration] Running upgrade 400f98739977 -> 6953534de441, add step to inputs table\n",
            "INFO  [alembic.runtime.migration] Running upgrade 6953534de441 -> bda7b8c39065, increase_model_version_tag_value_limit\n",
            "INFO  [alembic.runtime.migration] Running upgrade bda7b8c39065 -> cbc13b556ace, add V3 trace schema columns\n",
            "INFO  [alembic.runtime.migration] Running upgrade cbc13b556ace -> 770bee3ae1dd, add assessments table\n",
            "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
            "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
            "2025/08/08 17:14:25 INFO mlflow.tracking.fluent: Experiment with name 'test_functions' does not exist. Creating a new experiment.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Registrando modelo en MLflow: RandomForestClassifier\n",
            "Registrando modelo en MLflow: XGBClassifier\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "5a15e37a",
        "850b5354",
        "793467d4"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}